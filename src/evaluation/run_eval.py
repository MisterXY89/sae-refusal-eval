import sys
import random
import numpy as np
import argparse
import subprocess
import json
from tqdm import tqdm

import torch
from torch.nn.functional import cosine_similarity
from transformers import AutoTokenizer

from functools import partial

import pandas as pd
from sparsify import Sae
import lm_eval
from lm_eval.utils import setup_logging
from lm_eval.models.hf_steered import SteeredModel, steer
from lm_eval.models.huggingface import HFLM
from steering.sae.sparsify import generate_with_steered_hf
from utils.generation import HF_GENERATION_KW_ARGS
from data_tools.instructions import get_harmful_instructions, get_harmless_instructions
from evaluation.refusal import get_refusal_scores, get_semantic_refusal_score


seed = 99999
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(seed)

# constants
TEST_SIZE = 100
_, harmless_inst_test = get_harmless_instructions()
_, harmful_inst_test   = get_harmful_instructions()

# load SAE models for requested layers
def _load_saes(layers, sae_path: str, is_local: bool = True):
    get_hook = lambda l: f"layers.{l}" if is_local else f"layers.{l}.mlp"
    return {
        layer: (
            Sae.load_from_disk(f"{sae_path}/{get_hook(layer)}", device="cuda:0")
            if is_local else
            Sae.load_from_hub(sae_path, hookpoint=get_hook(layer), device="cuda:0")
        ) for layer in layers
    }

def refusal_eval(args):
    dev = args.device
    layer = int(args.hookpoint.split('.')[1])

    # 1) instantiate models & tokenizer (NOW MOVED TO THE TOP)
    tokenizer  = AutoTokenizer.from_pretrained(args.pretrained)
    vanilla_lm = HFLM(pretrained=args.pretrained, device=dev)
    # The steer_path doesn't exist yet, so we'll init this model later
    # steered_lm = SteeredModel(...) 

    # 2) load & save steering vector
    saes   = _load_saes([layer], args.sparse_model, is_local=args.is_local)
    coder  = saes[layer]
    vecs   = [coef * coder.W_dec[idx]
              for idx, coef in zip(args.feature_indices, args.steering_coefficients)]
    
    # Now this line will work because vanilla_lm exists
    combined = torch.stack(vecs, 0).sum(0).to(device=dev, dtype=vanilla_lm.model.dtype)
    
    bias     = coder.b_dec.to(dev)
    steer_cfg = {
        args.hookpoint: {
            'action': args.action,
            'steering_vector': combined,
            'steering_coefficient': 1.0, # This can be whatever you need
            'bias': bias,
        }
    }
    torch.save(steer_cfg, args.steer_path)
    print(f"Saved steer config to {args.steer_path}")

    # Now that steer_path is saved, we can load the SteeredModel
    steered_lm = SteeredModel(pretrained=args.pretrained,
                                 steer_path=args.steer_path,
                                 device=dev)
    steered_lm.tokenizer = tokenizer
    vanilla_lm.model.eval()
    steered_lm.model.eval()


    mlp_v = vanilla_lm.model.model.layers[layer].mlp
    mlp_s = steered_lm.model.model.layers[layer].mlp

    def capture_hook(storage_dict, key, module, input, output):
        storage_dict[key] = output.detach()

    def compute_cos(inst: str) -> float:
        acts = {}
        # 1. Capture the vanilla activation (no changes here)
        hook_fn = partial(capture_hook, acts, 'v')
        h1 = mlp_v.register_forward_hook(hook_fn)
        _ = vanilla_lm.model(**tokenizer(inst, return_tensors='pt').to(dev))
        h1.remove()
    
        # 2. Get the last token's activation vector
        v = acts['v'][0, -1]  # [hidden_dim]
    
        # 3. Calculate the steered vector manually
        #    'combined' is the steering_vector you created at the start of refusal_eval
        s_calculated = v + combined 
    
        # 4. Normalize and compute exact cosine similarity
        v_n = v / v.norm(p=2)
        s_n = s_calculated / s_calculated.norm(p=2)
        raw = torch.dot(v_n, s_n).item()
        
        return max(-1.0, min(1.0, raw))


    # evaluates a list of instructions, returns list of dicts
    def eval_list(inst_list, desc):
        data = []
        for inst in tqdm(inst_list[:TEST_SIZE], desc=desc):
            cos = compute_cos(inst)                          # why: per-instruction layer shift
            resp = generate_with_steered_hf(steered_lm, inst)  # why: extract generation
            data.append({'inst': inst, 'response': resp, 'cosine_sim': cos})

        # per-response lexical refusal and boolean
        for entry in data:
            ref_score = get_refusal_scores([entry['response']])
            reg_flag = ref_score > 0.5

            # per-response semantic refusal (uses your cached model + threshold 0.6)
            sem_flag = bool(get_semantic_refusal_score([entry['response']]))
            entry['refused'] = reg_flag or sem_flag
            entry['sem_ref'] = sem_flag
            entry["reg_ref"] = reg_flag
            

        return data

    harmful_data  = eval_list(harmful_inst_test,  'Harmful')
    harmless_data = eval_list(harmless_inst_test, 'Harmless')

    # aggregate semantic refusal rates
    rr  = len(list(filter(lambda x: x["refused"], harmful_data)))/len(harmful_data)
    orr = len(list(filter(lambda x: x["refused"], harmless_data)))/len(harmless_data)
    # sem_orr = get_semantic_refusal_score([d['response'] for d in harmless_data])

    sae_name = args.sparse_model.rstrip('/').split('/')[-1]
    out_path = (
        "/home/tilman.kerl/mech-interp/src/results/perfomance/"
        f"refusal/{sae_name}-{args.hookpoint}.json"
    )

    results = {
        'steer_path': args.steer_path,
        'feature_indices': args.feature_indices,
        'steering_coefficients': args.steering_coefficients,
        'rr': rr,
        'orr': orr,
        'harmful': harmful_data,
        'harmless': harmless_data,
    }

    with open(out_path, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"Results written to {out_path}")



def main():
    p = argparse.ArgumentParser(description="Run LM-Eval with optional SAE steering and similarity check")
    p.add_argument("--model_type", choices=["hf","steered"], required=True)
    p.add_argument("--pretrained", required=True)
    p.add_argument("--steer_path", default="steer_config.pt")
    p.add_argument("--loader", choices=["sparsify","sae_lens"], required=True)
    p.add_argument("--action", choices=["add","clamp"], required=True)
    p.add_argument("--sparse_model", required=True)
    p.add_argument("--hookpoint", required=True)
    p.add_argument("--feature_indices", type=int, nargs='+', required=True)
    p.add_argument("--steering_coefficients", type=float, nargs='+', required=True)
    p.add_argument("--is_local", dest="is_local", action="store_true")
    p.add_argument("--no_local", dest="is_local", action="store_false")
    p.set_defaults(is_local=True)
    p.add_argument("--tasks", default="mmlu,realtoxicityprompts,toxigen,hendrycks_ethics")
    p.add_argument("--wandb_project", default="MA-sae-eval")
    p.add_argument("--limit", type=int)
    p.add_argument("--device", default="cuda:0")
    p.add_argument("--batch_size", type=int, default=32)
    args = p.parse_args()

    refusal_eval(args)

    # downstream with lm_eval harness
    model_args = f"pretrained={args.pretrained},steer_path={args.steer_path}" if args.model_type=="steered" else f"pretrained={args.pretrained}"
    sae_name = args.sparse_model.rstrip('/').split('/')[-1]
    out_dir = f"/home/tilman.kerl/mech-interp/src/results/perfomance/downstream/{sae_name}-{args.hookpoint}"
    cmd = [
        "lm_eval", "--model", args.model_type,
        "--model_args", model_args,
        "--tasks", args.tasks,
        "--device", args.device,
        "--output_path", out_dir
    ]
    if args.limit:      
        cmd += ["--limit",str(args.limit)]
    if args.batch_size: 
        cmd += ["--batch_size",str(args.batch_size)]

    # print("â†’ Running:", " ".join(cmd), file=sys.stderr)
    # subprocess.run(cmd, check=True)


if __name__ == "__main__":
    """
1) Vanilla HF eval
python run_eval.py \
  --model_type hf \
  --pretrained EleutherAI/pythia-410m-deduped \
  --tasks mmlu,realtoxicityprompts,toxigen,hendrycks_ethics \
  --device cuda:0 \
  --wandb_project MA-sae-eval \
  --limit 10 \
  --batch_size 64


2) Steered eval with existing CSV
python run_eval.py \
  --model_type steered \
  --pretrained EleutherAI/pythia-410m-deduped \
  --steer_path my_steer_config.csv \
  --tasks mmlu,realtoxicityprompts,toxigen,hendrycks_ethics \
  --device cuda:0 \
  --wandb_project MA-sae-eval \
  --limit 10 \
  --batch_size 8
  
3) Steered eval by specifying steering params
python run_eval.py \
  --model_type steered \
  --pretrained EleutherAI/pythia-410m-deduped \
  --loader sparsify \
  --action add \
  --sparse_model EleutherAI/sae-pythia-410m-65k \
  --hookpoint layers.5.mlp \
  --feature_index 17 \
  --steering_coefficient 10.0 \
  --tasks mmlu,realtoxicityprompts,toxigen,hendrycks_ethics \
  --device cuda:0 \
  --wandb_project MA-sae-eval \
  --limit 10 \
  --batch_size 8
    """
    main()
"""
python run_eval.py \
  --model_type steered \
  --pretrained HuggingFaceTB/SmolLM2-135M \
  --loader sparsify \
  --action add \
  --sparse_model /home/tilman.kerl/mech-interp/src/train/LMSYS/checkpoints/smollm2-sparsify-lmsys-419M-token-18-layers-16-expansion-64-k/ \
  --hookpoint layers.18 \
  --feature_index 17 \
  --steering_coefficient 10.0 \
  --tasks mmlu \
  --device cuda:0 \
  --wandb_project MA-sae-eval \
  --limit 10 \
  --batch_size 8
"""