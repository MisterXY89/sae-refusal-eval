_wandb:
    value:
        cli_version: 0.19.8
        m: []
        python_version: 3.11.11
        t:
            "1":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 95
                - 98
                - 100
                - 105
            "2":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 95
                - 98
                - 100
                - 105
            "3":
                - 2
                - 23
                - 55
                - 62
            "4": 3.11.11
            "5": 0.19.8
            "6": 4.51.3
            "8":
                - 5
            "12": 0.19.8
            "13": linux-x86_64
cli_configs:
    value:
        batch_size: 1
        batch_sizes: []
        bootstrap_iters: 100000
        device: cuda:0
        fewshot_seed: 1234
        gen_kwargs: null
        limit: 10
        model: hf
        model_args: pretrained=EleutherAI/pythia-410m-deduped
        model_dtype: torch.float16
        model_num_parameters: 405334016
        model_revision: main
        model_sha: c4fc8d586d62df497f1f9b69d66d3ca419992d3e
        numpy_seed: 1234
        random_seed: 0
        torch_seed: 1234
        use_cache: null
task_configs:
    value:
        mmlu_abstract_algebra:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: abstract_algebra
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about abstract algebra.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_abstract_algebra
            task_alias: abstract_algebra
            test_split: test
            unsafe_code: false
        mmlu_anatomy:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: anatomy
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about anatomy.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_anatomy
            task_alias: anatomy
            test_split: test
            unsafe_code: false
        mmlu_astronomy:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: astronomy
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about astronomy.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_astronomy
            task_alias: astronomy
            test_split: test
            unsafe_code: false
        mmlu_business_ethics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: business_ethics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about business ethics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_business_ethics
            task_alias: business_ethics
            test_split: test
            unsafe_code: false
        mmlu_clinical_knowledge:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: clinical_knowledge
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about clinical knowledge.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_clinical_knowledge
            task_alias: clinical_knowledge
            test_split: test
            unsafe_code: false
        mmlu_college_biology:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: college_biology
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about college biology.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_college_biology
            task_alias: college_biology
            test_split: test
            unsafe_code: false
        mmlu_college_chemistry:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: college_chemistry
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about college chemistry.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_college_chemistry
            task_alias: college_chemistry
            test_split: test
            unsafe_code: false
        mmlu_college_computer_science:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: college_computer_science
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about college computer science.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_college_computer_science
            task_alias: college_computer_science
            test_split: test
            unsafe_code: false
        mmlu_college_mathematics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: college_mathematics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about college mathematics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_college_mathematics
            task_alias: college_mathematics
            test_split: test
            unsafe_code: false
        mmlu_college_medicine:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: college_medicine
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about college medicine.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_college_medicine
            task_alias: college_medicine
            test_split: test
            unsafe_code: false
        mmlu_college_physics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: college_physics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about college physics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_college_physics
            task_alias: college_physics
            test_split: test
            unsafe_code: false
        mmlu_computer_security:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: computer_security
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about computer security.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_computer_security
            task_alias: computer_security
            test_split: test
            unsafe_code: false
        mmlu_conceptual_physics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: conceptual_physics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about conceptual physics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_conceptual_physics
            task_alias: conceptual_physics
            test_split: test
            unsafe_code: false
        mmlu_econometrics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: econometrics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about econometrics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_econometrics
            task_alias: econometrics
            test_split: test
            unsafe_code: false
        mmlu_electrical_engineering:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: electrical_engineering
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about electrical engineering.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_electrical_engineering
            task_alias: electrical_engineering
            test_split: test
            unsafe_code: false
        mmlu_elementary_mathematics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: elementary_mathematics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about elementary mathematics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_elementary_mathematics
            task_alias: elementary_mathematics
            test_split: test
            unsafe_code: false
        mmlu_formal_logic:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: formal_logic
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about formal logic.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_formal_logic
            task_alias: formal_logic
            test_split: test
            unsafe_code: false
        mmlu_global_facts:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: global_facts
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about global facts.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_global_facts
            task_alias: global_facts
            test_split: test
            unsafe_code: false
        mmlu_high_school_biology:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_biology
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school biology.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_high_school_biology
            task_alias: high_school_biology
            test_split: test
            unsafe_code: false
        mmlu_high_school_chemistry:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_chemistry
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school chemistry.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_high_school_chemistry
            task_alias: high_school_chemistry
            test_split: test
            unsafe_code: false
        mmlu_high_school_computer_science:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_computer_science
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school computer science.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_high_school_computer_science
            task_alias: high_school_computer_science
            test_split: test
            unsafe_code: false
        mmlu_high_school_european_history:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_european_history
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school european history.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_high_school_european_history
            task_alias: high_school_european_history
            test_split: test
            unsafe_code: false
        mmlu_high_school_geography:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_geography
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school geography.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_high_school_geography
            task_alias: high_school_geography
            test_split: test
            unsafe_code: false
        mmlu_high_school_government_and_politics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_government_and_politics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school government and politics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_high_school_government_and_politics
            task_alias: high_school_government_and_politics
            test_split: test
            unsafe_code: false
        mmlu_high_school_macroeconomics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_macroeconomics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school macroeconomics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_high_school_macroeconomics
            task_alias: high_school_macroeconomics
            test_split: test
            unsafe_code: false
        mmlu_high_school_mathematics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_mathematics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school mathematics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_high_school_mathematics
            task_alias: high_school_mathematics
            test_split: test
            unsafe_code: false
        mmlu_high_school_microeconomics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_microeconomics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school microeconomics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_high_school_microeconomics
            task_alias: high_school_microeconomics
            test_split: test
            unsafe_code: false
        mmlu_high_school_physics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_physics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school physics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_high_school_physics
            task_alias: high_school_physics
            test_split: test
            unsafe_code: false
        mmlu_high_school_psychology:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_psychology
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school psychology.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_high_school_psychology
            task_alias: high_school_psychology
            test_split: test
            unsafe_code: false
        mmlu_high_school_statistics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_statistics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school statistics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_high_school_statistics
            task_alias: high_school_statistics
            test_split: test
            unsafe_code: false
        mmlu_high_school_us_history:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_us_history
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school us history.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_high_school_us_history
            task_alias: high_school_us_history
            test_split: test
            unsafe_code: false
        mmlu_high_school_world_history:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: high_school_world_history
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about high school world history.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_high_school_world_history
            task_alias: high_school_world_history
            test_split: test
            unsafe_code: false
        mmlu_human_aging:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: human_aging
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about human aging.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_human_aging
            task_alias: human_aging
            test_split: test
            unsafe_code: false
        mmlu_human_sexuality:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: human_sexuality
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about human sexuality.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_human_sexuality
            task_alias: human_sexuality
            test_split: test
            unsafe_code: false
        mmlu_international_law:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: international_law
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about international law.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_international_law
            task_alias: international_law
            test_split: test
            unsafe_code: false
        mmlu_jurisprudence:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: jurisprudence
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about jurisprudence.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_jurisprudence
            task_alias: jurisprudence
            test_split: test
            unsafe_code: false
        mmlu_logical_fallacies:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: logical_fallacies
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about logical fallacies.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_logical_fallacies
            task_alias: logical_fallacies
            test_split: test
            unsafe_code: false
        mmlu_machine_learning:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: machine_learning
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about machine learning.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_stem_tasks
            target_delimiter: ' '
            task: mmlu_machine_learning
            task_alias: machine_learning
            test_split: test
            unsafe_code: false
        mmlu_management:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: management
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about management.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_management
            task_alias: management
            test_split: test
            unsafe_code: false
        mmlu_marketing:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: marketing
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about marketing.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_marketing
            task_alias: marketing
            test_split: test
            unsafe_code: false
        mmlu_medical_genetics:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: medical_genetics
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about medical genetics.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_medical_genetics
            task_alias: medical_genetics
            test_split: test
            unsafe_code: false
        mmlu_miscellaneous:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: miscellaneous
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about miscellaneous.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_miscellaneous
            task_alias: miscellaneous
            test_split: test
            unsafe_code: false
        mmlu_moral_disputes:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: moral_disputes
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about moral disputes.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_moral_disputes
            task_alias: moral_disputes
            test_split: test
            unsafe_code: false
        mmlu_moral_scenarios:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: moral_scenarios
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about moral scenarios.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_moral_scenarios
            task_alias: moral_scenarios
            test_split: test
            unsafe_code: false
        mmlu_nutrition:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: nutrition
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about nutrition.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_nutrition
            task_alias: nutrition
            test_split: test
            unsafe_code: false
        mmlu_philosophy:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: philosophy
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about philosophy.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_philosophy
            task_alias: philosophy
            test_split: test
            unsafe_code: false
        mmlu_prehistory:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: prehistory
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about prehistory.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_prehistory
            task_alias: prehistory
            test_split: test
            unsafe_code: false
        mmlu_professional_accounting:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: professional_accounting
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about professional accounting.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_professional_accounting
            task_alias: professional_accounting
            test_split: test
            unsafe_code: false
        mmlu_professional_law:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: professional_law
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about professional law.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_professional_law
            task_alias: professional_law
            test_split: test
            unsafe_code: false
        mmlu_professional_medicine:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: professional_medicine
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about professional medicine.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_professional_medicine
            task_alias: professional_medicine
            test_split: test
            unsafe_code: false
        mmlu_professional_psychology:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: professional_psychology
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about professional psychology.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_professional_psychology
            task_alias: professional_psychology
            test_split: test
            unsafe_code: false
        mmlu_public_relations:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: public_relations
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about public relations.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_public_relations
            task_alias: public_relations
            test_split: test
            unsafe_code: false
        mmlu_security_studies:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: security_studies
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about security studies.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_security_studies
            task_alias: security_studies
            test_split: test
            unsafe_code: false
        mmlu_sociology:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: sociology
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about sociology.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_sociology
            task_alias: sociology
            test_split: test
            unsafe_code: false
        mmlu_us_foreign_policy:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: us_foreign_policy
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about us foreign policy.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_social_sciences_tasks
            target_delimiter: ' '
            task: mmlu_us_foreign_policy
            task_alias: us_foreign_policy
            test_split: test
            unsafe_code: false
        mmlu_virology:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: virology
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about virology.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_other_tasks
            target_delimiter: ' '
            task: mmlu_virology
            task_alias: virology
            test_split: test
            unsafe_code: false
        mmlu_world_religions:
            dataset_kwargs:
                trust_remote_code: true
            dataset_name: world_religions
            dataset_path: cais/mmlu
            description: |+
                The following are multiple choice questions (with answers) about world religions.

            doc_to_choice:
                - A
                - B
                - C
                - D
            doc_to_target: answer
            doc_to_text: |-
                {{question.strip()}}
                A. {{choices[0]}}
                B. {{choices[1]}}
                C. {{choices[2]}}
                D. {{choices[3]}}
                Answer:
            fewshot_config:
                sampler: first_n
            fewshot_delimiter: |4+

            fewshot_split: dev
            metadata:
                pretrained: EleutherAI/pythia-410m-deduped
                version: 1
            metric_list:
                - aggregation: mean
                  higher_is_better: true
                  metric: acc
            num_fewshot: 0
            output_type: multiple_choice
            repeats: 1
            should_decontaminate: false
            tag: mmlu_humanities_tasks
            target_delimiter: ' '
            task: mmlu_world_religions
            task_alias: world_religions
            test_split: test
            unsafe_code: false
