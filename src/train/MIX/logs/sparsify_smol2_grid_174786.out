################  DATASET = MisterXY89/pre_dominant_70_30  ################
==> Run smollm2-sparsify-PRE-419M-token-6_25-layers-8-expansion-64-k
W0620 00:24:23.139000 2236888 site-packages/torch/distributed/run.py:792] 
W0620 00:24:23.139000 2236888 site-packages/torch/distributed/run.py:792] *****************************************
W0620 00:24:23.139000 2236888 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0620 00:24:23.139000 2236888 site-packages/torch/distributed/run.py:792] *****************************************
Using DDP across 2 GPUs.
[rank0]: Traceback (most recent call last):
[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:   File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/sparsify/__main__.py", line 197, in <module>
[rank0]:     run()
[rank0]:   File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/sparsify/__main__.py", line 163, in run
[rank0]:     model, dataset = load_artifacts(args, rank)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/sparsify/__main__.py", line 104, in load_artifacts
[rank0]:     dataset = load_dataset(
[rank0]:               ^^^^^^^^^^^^^
[rank0]:   File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/datasets/load.py", line 2606, in load_dataset
[rank0]:     builder_instance = load_dataset_builder(
[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/datasets/load.py", line 2277, in load_dataset_builder
[rank0]:     dataset_module = dataset_module_factory(
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/datasets/load.py", line 1917, in dataset_module_factory
[rank0]:     raise e1 from None
[rank0]:   File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/datasets/load.py", line 1867, in dataset_module_factory
[rank0]:     raise DatasetNotFoundError(f"Dataset '{path}' doesn't exist on the Hub or cannot be accessed.") from e
[rank0]: datasets.exceptions.DatasetNotFoundError: Dataset 'MisterXY89/pre_dominant_70_30' doesn't exist on the Hub or cannot be accessed.
[rank0]:[W620 00:24:31.268352786 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W0620 00:24:32.977000 2236888 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2236900 closing signal SIGTERM
E0620 00:24:33.344000 2236888 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 2236899) of binary: /home/tilman.kerl/miniconda3/envs/refusal/bin/python
Traceback (most recent call last):
  File "/home/tilman.kerl/miniconda3/envs/refusal/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/tilman.kerl/miniconda3/envs/refusal/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
sparsify FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-06-20_00:24:32
  host      : a-a100-o-1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2236899)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
